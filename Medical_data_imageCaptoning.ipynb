{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b346dee9612443ebb50fa15c0776e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fc74eededc844a3a60d1991a6f3ff9e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41fb59f92a5b470eb5ca46f88da5bc00",
              "IPY_MODEL_11405ab5e54a46839a47862305090cd0",
              "IPY_MODEL_2aa8b107e1864aea8a48fc449a18e69b"
            ]
          }
        },
        "2fc74eededc844a3a60d1991a6f3ff9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41fb59f92a5b470eb5ca46f88da5bc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b130feaec3547428609c006a966dc92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bcbdb8bf76e4b2aa366dbb1c6c4f23a"
          }
        },
        "11405ab5e54a46839a47862305090cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8aab60baa4e34261940b1565a05f7084",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 205,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 205,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83765791877542fd8d512f01b36065ab"
          }
        },
        "2aa8b107e1864aea8a48fc449a18e69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e737609f8474ca095bc89f05b30c378",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 205/205 [03:29&lt;00:00,  1.05it/s, lr=0.0001, train_loss=3.99]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_032a5b070fca4d518de0b0e834cb8ce5"
          }
        },
        "0b130feaec3547428609c006a966dc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bcbdb8bf76e4b2aa366dbb1c6c4f23a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8aab60baa4e34261940b1565a05f7084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83765791877542fd8d512f01b36065ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e737609f8474ca095bc89f05b30c378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "032a5b070fca4d518de0b0e834cb8ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2aad45036ed451493e19b4a7273bb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d00457ddd200439ebe52e835f0fadb8d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_813b8b813b844cf89b526dd10c7a3939",
              "IPY_MODEL_165b6e337e3d4bc2a711dbbc2415f723",
              "IPY_MODEL_78bed4ebcc7146a3a2b218ac5d74fde6"
            ]
          }
        },
        "d00457ddd200439ebe52e835f0fadb8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "813b8b813b844cf89b526dd10c7a3939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa3a5031b439493a9261f360f4673e55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 68%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2adbe6b07a6747a8a6e9bfce8d0eb293"
          }
        },
        "165b6e337e3d4bc2a711dbbc2415f723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7d5c7a5110984644a22da7e879c6e5a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1843,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1245,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d54e3ecb8d134a5eb8563b76cc510e72"
          }
        },
        "78bed4ebcc7146a3a2b218ac5d74fde6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2186d4488c74288be6c514f45ae9b4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1245/1843 [32:20&lt;17:29,  1.76s/it, valid_loss=2.54]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6703cc11a5444e96845db0e1e4f5e6ab"
          }
        },
        "aa3a5031b439493a9261f360f4673e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2adbe6b07a6747a8a6e9bfce8d0eb293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d5c7a5110984644a22da7e879c6e5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d54e3ecb8d134a5eb8563b76cc510e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2186d4488c74288be6c514f45ae9b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6703cc11a5444e96845db0e1e4f5e6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4vQXRqNwXjf"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSvBQoszjYJS"
      },
      "source": [
        "!pip install timm\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvXzfQqgi6lT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd5cb6d-f681-4563-e90f-d14d7062b26f"
      },
      "source": [
        "from IPython import display as ipythondisplay\n",
        "from torch import nn\n",
        "from tqdm.autonotebook import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import gc\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF8XzKlSi6lT"
      },
      "source": [
        "## Some pre-preocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieBwPS2Qi6lT",
        "outputId": "b70c6245-4d23-46c7-a328-f1d7fbecaa51"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/Shareddrives/DeepLearning/datav2/dataset.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA9TJM4Z8Bt-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9b11d214-96c1-417a-99fc-040f5859619f"
      },
      "source": [
        "\n",
        "# Ops to consolidate dataset to the notebook standards\n",
        "\n",
        "# Create a compound column using other columns. Comment lines for less or more complexity\n",
        "\n",
        "# \"a sagital plane\n",
        "# MR scan\n",
        "# of cranial trauma\n",
        "# on a 58 year old male\n",
        "# diagnosed with brain death\n",
        "df[\"grouped_diag\"] = df.apply(lambda row: \\\n",
        "                              \"a \" + str(row.Plane) + \" plane \"\\\n",
        "                              + str(row.Core_Modality) + \" scan\"\\\n",
        "                              + \" of \"  + str(row.Location) + \" \" + str(row.Category)\\\n",
        "                              + \" on a \" + str(row.Patient_Age) + \" year old \" + str(row.Patient_Gender)\n",
        "                              + \" depicting \"+ str(row.Case_Diagnosis)\n",
        "                              , axis = 1)\n",
        "\n",
        "\n",
        "#  reformat to fit the shape\n",
        "#  \timage \tcaption id\n",
        "df.rename(columns={\"filename\":\"image\", \"grouped_diag\":\"caption\"},inplace=True)\n",
        "needed_cols = [\"image\",\"caption\"]\n",
        "df = df[df.columns.intersection(needed_cols)]\n",
        "\n",
        "image_path = \"/content/drive/Shareddrives/DeepLearning/datav2/output\"\n",
        "captions_path = \"/content/drive/Shareddrives/DeepLearning/datav2\"\n",
        "\n",
        "#  \timage \tcaption\n",
        "# 0 \t1000268201_693b08cb0e.jpg \tA child in a pink dress is climbing up a set o...\n",
        "# 1 \t1000268201_693b08cb0e.jpg \tA girl going into a wooden building .\n",
        "# 2 \t1000268201_693b08cb0e.jpg \tA little girl climbing into a wooden playhouse .\n",
        "# 3 \t1000268201_693b08cb0e.jpg \tA little girl climbing the stairs to her playh...\n",
        "# 4 \t1000268201_693b08cb0e.jpg \tA little girl in a pink dress going into a woo...\n",
        "\n",
        "# I have no idea why tf he writes the dataset to memory but whatev\n",
        "df.to_csv(captions_path + \"/captions.csv\", index=False)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>synpic100377.jpg</td>\n",
              "      <td>a Multiple or Montage plane CT scan of Musculo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>synpic100378.jpg</td>\n",
              "      <td>a Multiple or Montage plane CT scan of Musculo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>synpic100379.jpg</td>\n",
              "      <td>a Multiple or Montage plane CT scan of Musculo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>synpic100380.jpg</td>\n",
              "      <td>a Oblique plane XR scan of Musculoskeletal Tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synpic100381.jpg</td>\n",
              "      <td>a Multiple or Montage plane MR scan of Musculo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              image                                            caption\n",
              "0  synpic100377.jpg  a Multiple or Montage plane CT scan of Musculo...\n",
              "1  synpic100378.jpg  a Multiple or Montage plane CT scan of Musculo...\n",
              "2  synpic100379.jpg  a Multiple or Montage plane CT scan of Musculo...\n",
              "3  synpic100380.jpg  a Oblique plane XR scan of Musculoskeletal Tra...\n",
              "4  synpic100381.jpg  a Multiple or Montage plane MR scan of Musculo..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib2zXV4r8Ayq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ulGHg9ai6lV"
      },
      "source": [
        "class CFG:\n",
        "    debug = False\n",
        "    image_path = image_path\n",
        "    captions_path = captions_path\n",
        "    batch_size = 12\n",
        "    num_workers = 2\n",
        "    head_lr = 1e-3\n",
        "    image_encoder_lr = 1e-4\n",
        "    text_encoder_lr = 1e-5\n",
        "    weight_decay = 1e-3\n",
        "    patience = 1\n",
        "    factor = 0.8\n",
        "    epochs = 2\n",
        "    saved_model_clinical = '/content/drive/Shareddrives/DeepLearning/datav2/withDiagnostics2.pt'\n",
        "    trained_model = 'clinical_bert_weights.pt'\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model_name = 'resnet50'\n",
        "    image_embedding = 2048\n",
        "    text_encoder_model = \"distilbert-base-uncased\"\n",
        "    clinical_encoder_model = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "    text_embedding = 768\n",
        "    text_tokenizer = \"distilbert-base-uncased\"\n",
        "    max_length = 200\n",
        "\n",
        "    pretrained = True # for both image encoder and text encoder\n",
        "    trainable = True # for both image encoder and text encoder\n",
        "    temperature = 1.0\n",
        "\n",
        "    # image size\n",
        "    size = 224\n",
        "\n",
        "    # for projection head; used for both image and text encoders\n",
        "    num_projection_layers = 1\n",
        "    projection_dim = 256\n",
        "    dropout = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sedGLtLO8Ku-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def make_train_valid_dfs():\n",
        "    dataframe = pd.read_csv(f\"{CFG.captions_path}/captions.csv\")\n",
        "    train, test = train_test_split(dataframe, test_size=.1, train_size=.9, shuffle=True, random_state=77,stratify=None)\n",
        "    return train, test\n",
        "\n",
        "testing_df , training_df = make_train_valid_dfs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_piLd4dxi6lV"
      },
      "source": [
        "class AvgMeter:\n",
        "    def __init__(self, name=\"Metric\"):\n",
        "        self.name = name\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.avg, self.sum, self.count = [0] * 3\n",
        "\n",
        "    def update(self, val, count=1):\n",
        "        self.count += count\n",
        "        self.sum += val * count\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __repr__(self):\n",
        "        text = f\"{self.name}: {self.avg:.4f}\"\n",
        "        return text\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group[\"lr\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM65_Loji6lW"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9V91XcNi6lW"
      },
      "source": [
        "# Custom dataset object. Will tokenize text and apply transforms to images before yielding them.\n",
        "\n",
        "class CLIPDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_filenames, captions, tokenizer, transforms):\n",
        "        \"\"\"\n",
        "        image_filenames and cpations must have the same length; so, if there are\n",
        "        multiple captions for each image, the image_filenames must have repetitive\n",
        "        file names\n",
        "        \"\"\"\n",
        "\n",
        "        self.image_filenames = image_filenames\n",
        "        self.captions = list(captions)\n",
        "        self.skippedImgCount = 0\n",
        "        self.encoded_captions = tokenizer(\n",
        "            list(captions), padding=True, truncation=True, max_length=CFG.max_length\n",
        "        )\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            key: torch.tensor(values[idx])\n",
        "            for key, values in self.encoded_captions.items()\n",
        "        }\n",
        "        ################################\n",
        "        # MASSIVE GDRIVE BUG HERE\n",
        "        # Sometimes, reading an image from disk fails, which crashes the entirety of the program\n",
        "        # Here we default to adding the image at dataset[0]\n",
        "        ################################\n",
        "        image = cv2.imread(f\"{CFG.image_path}/{self.image_filenames[idx]}\")\n",
        "        if image is None:\n",
        "          self.skippedImgCount += 1\n",
        "          return self.__getitem__(1)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = self.transforms(image=image)['image']\n",
        "        item['image'] = torch.tensor(image).permute(2, 0, 1).float()\n",
        "        item['caption'] = self.captions[idx]\n",
        "\n",
        "        return item\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.captions)\n",
        "\n",
        "\n",
        "\n",
        "def get_transforms(mode=\"train\"):\n",
        "    if mode == \"train\":\n",
        "        return A.Compose(\n",
        "            [\n",
        "                A.Resize(CFG.size, CFG.size, always_apply=True),\n",
        "                A.Normalize(max_pixel_value=255.0, always_apply=True),\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        return A.Compose(\n",
        "            [\n",
        "                A.Resize(CFG.size, CFG.size, always_apply=True),\n",
        "                A.Normalize(max_pixel_value=255.0, always_apply=True),\n",
        "            ]\n",
        "        )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk394aMmi6lX"
      },
      "source": [
        "## Image Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0flfMTRi6lY"
      },
      "source": [
        "class ImageEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encode images to a fixed size vector\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, model_name=CFG.model_name, pretrained=CFG.pretrained, trainable=CFG.trainable\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(\n",
        "            model_name, pretrained, num_classes=0, global_pool=\"avg\"\n",
        "        )\n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad = trainable\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKRoQ0o9i6lY"
      },
      "source": [
        "## Text Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am5VR4Ezi6lZ"
      },
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, model_name=CFG.text_encoder_model, pretrained=CFG.pretrained, trainable=CFG.trainable):\n",
        "        super().__init__()\n",
        "        if pretrained:\n",
        "            # self.model = DistilBertModel.from_pretrained(model_name)\n",
        "\n",
        "            # Use Bio-ClinicalBERT\n",
        "            self.model = AutoModel.from_pretrained(CFG.clinical_encoder_model)\n",
        "\n",
        "        else:\n",
        "            self.model = DistilBertModel(config=DistilBertConfig())\n",
        "\n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad = trainable\n",
        "\n",
        "        # we are using the CLS token hidden representation as the sentence's embedding\n",
        "        self.target_token_idx = 0\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = output.last_hidden_state\n",
        "        return last_hidden_state[:, self.target_token_idx, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDKLE4cKi6lZ"
      },
      "source": [
        "## Projection Head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJbY9Yrui6la"
      },
      "source": [
        "# Get both image and text encodings into a same size matrix\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim,\n",
        "        projection_dim=CFG.projection_dim,\n",
        "        dropout=CFG.dropout\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        projected = self.projection(x)\n",
        "        x = self.gelu(projected)\n",
        "        x = self.fc(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + projected\n",
        "        x = self.layer_norm(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MQnmwsWi6lc"
      },
      "source": [
        "class CLIPModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        temperature=CFG.temperature,\n",
        "        image_embedding=CFG.image_embedding,\n",
        "        text_embedding=CFG.text_embedding,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.text_encoder = TextEncoder()\n",
        "        self.image_projection = ProjectionHead(embedding_dim=image_embedding)\n",
        "        self.text_projection = ProjectionHead(embedding_dim=text_embedding)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # Getting Image and Text Features\n",
        "        image_features = self.image_encoder(batch[\"image\"])\n",
        "        text_features = self.text_encoder(\n",
        "            input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n",
        "        )\n",
        "        # Getting Image and Text Embeddings (with same dimension)\n",
        "        image_embeddings = self.image_projection(image_features)\n",
        "        text_embeddings = self.text_projection(text_features)\n",
        "\n",
        "        # Calculating the Loss\n",
        "        logits = (text_embeddings @ image_embeddings.T) / self.temperature\n",
        "        images_similarity = image_embeddings @ image_embeddings.T\n",
        "        texts_similarity = text_embeddings @ text_embeddings.T\n",
        "        targets = F.softmax(\n",
        "            (images_similarity + texts_similarity) / 2 * self.temperature, dim=-1\n",
        "        )\n",
        "        texts_loss = cross_entropy(logits, targets, reduction='none')\n",
        "        images_loss = cross_entropy(logits.T, targets.T, reduction='none')\n",
        "        loss =  (images_loss + texts_loss) / 2.0 # shape: (batch_size)\n",
        "        return loss.mean()\n",
        "\n",
        "\n",
        "def cross_entropy(preds, targets, reduction='none'):\n",
        "    log_softmax = nn.LogSoftmax(dim=-1)\n",
        "    loss = (-targets * log_softmax(preds)).sum(1)\n",
        "    if reduction == \"none\":\n",
        "        return loss\n",
        "    elif reduction == \"mean\":\n",
        "        return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9d2rsBNwqUe"
      },
      "source": [
        "The perfect relationship between encoded images and captions is described by their encoded representations being the same.\n",
        "This similarity can easily be measured by looking at the softmax between the dot product of the encoded inputs; a perfect encoding will yield the identity matrix.\n",
        "The loss on each iteration is calculated using cross entropy on the dot product between the encodings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgDm0OYYi6lc",
        "outputId": "f4e1c130-6b66-4e71-dc33-1aa37ce985e0"
      },
      "source": [
        "# A simple Example\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "dim = 256\n",
        "embeddings = torch.randn(batch_size, dim)\n",
        "out = embeddings @ embeddings.T\n",
        "print(F.softmax(out, dim=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXkzSurfi6ld"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUSC32Cei6ld"
      },
      "source": [
        "\n",
        "\n",
        "def build_loaders(dataframe, tokenizer, mode):\n",
        "    transforms = get_transforms(mode=mode)\n",
        "    dataset = CLIPDataset(\n",
        "        dataframe[\"image\"].values,\n",
        "        dataframe[\"caption\"].values,\n",
        "        tokenizer=tokenizer,\n",
        "        transforms=transforms,\n",
        "    )\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=CFG.batch_size,\n",
        "        num_workers=CFG.num_workers,\n",
        "        shuffle=True if mode == \"train\" else False,\n",
        "    )\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzilIObk-XKq"
      },
      "source": [
        "\n",
        "class PeriodicPlotter:\n",
        "  def __init__(self, sec, xlabel='', ylabel='', scale=None):\n",
        "\n",
        "    self.xlabel = xlabel\n",
        "    self.ylabel = ylabel\n",
        "    self.sec = sec\n",
        "    self.scale = scale\n",
        "\n",
        "    self.tic = time.time()\n",
        "\n",
        "  def plot(self, data):\n",
        "    if time.time() - self.tic > self.sec:\n",
        "      plt.cla()\n",
        "\n",
        "      if self.scale is None:\n",
        "        plt.plot(data)\n",
        "      elif self.scale == 'semilogx':\n",
        "        plt.semilogx(data)\n",
        "      elif self.scale == 'semilogy':\n",
        "        plt.semilogy(data)\n",
        "      elif self.scale == 'loglog':\n",
        "        plt.loglog(data)\n",
        "      else:\n",
        "        raise ValueError(\"unrecognized parameter scale {}\".format(self.scale))\n",
        "\n",
        "      plt.xlabel(self.xlabel); plt.ylabel(self.ylabel)\n",
        "      ipythondisplay.clear_output(wait=True)\n",
        "\n",
        "      ipythondisplay.display(plt.gcf())\n",
        "\n",
        "      self.tic = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkjp0BEPi6le"
      },
      "source": [
        "def train_epoch(model, train_loader, optimizer, lr_scheduler, step):\n",
        "    plotter = PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
        "    loss_meter = AvgMeter()\n",
        "    tqdm_object = tqdm(train_loader, total=len(train_loader))\n",
        "    history = []\n",
        "    for batch in tqdm_object:\n",
        "        batch = {k: v.to(CFG.device) for k, v in batch.items() if k != \"caption\"}\n",
        "        loss = model(batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if step == \"batch\":\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        count = batch[\"image\"].size(0)\n",
        "\n",
        "\n",
        "        loss_meter.update(loss.item(), count)\n",
        "\n",
        "        history.append(loss.cpu().detach().numpy().mean())\n",
        "\n",
        "        tqdm_object.set_postfix(train_loss=loss_meter.avg, lr=get_lr(optimizer))\n",
        "    plotter.plot(history)\n",
        "    return loss_meter\n",
        "\n",
        "\n",
        "def valid_epoch(model, valid_loader):\n",
        "    loss_meter = AvgMeter()\n",
        "\n",
        "    tqdm_object = tqdm(valid_loader, total=len(valid_loader))\n",
        "    for batch in tqdm_object:\n",
        "        batch = {k: v.to(CFG.device) for k, v in batch.items() if k != \"caption\"}\n",
        "        loss = model(batch)\n",
        "\n",
        "        count = batch[\"image\"].size(0)\n",
        "        loss_meter.update(loss.item(), count)\n",
        "\n",
        "        tqdm_object.set_postfix(valid_loss=loss_meter.avg)\n",
        "    return loss_meter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    train_df = training_df\n",
        "    valid_df = testing_df\n",
        "    # tokenizer = DistilBertTokenizer.from_pretrained(CFG.text_tokenizer)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CFG.clinical_encoder_model)\n",
        "    train_loader = build_loaders(train_df, tokenizer, mode=\"train\")\n",
        "    valid_loader = build_loaders(valid_df, tokenizer, mode=\"valid\")\n",
        "\n",
        "\n",
        "    model = CLIPModel().to(CFG.device)\n",
        "    params = [\n",
        "        {\"params\": model.image_encoder.parameters(), \"lr\": CFG.image_encoder_lr},\n",
        "        {\"params\": model.text_encoder.parameters(), \"lr\": CFG.text_encoder_lr},\n",
        "        {\"params\": itertools.chain(\n",
        "            model.image_projection.parameters(), model.text_projection.parameters()\n",
        "        ), \"lr\": CFG.head_lr, \"weight_decay\": CFG.weight_decay}\n",
        "    ]\n",
        "    optimizer = torch.optim.AdamW(params, weight_decay=0.)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"min\", patience=CFG.patience, factor=CFG.factor\n",
        "    )\n",
        "    step = \"epoch\"\n",
        "\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    history = []\n",
        "    for epoch in range(CFG.epochs):\n",
        "        print(f\"Epoch: {epoch + 1}\")\n",
        "        model.train()\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, lr_scheduler, step)\n",
        "        model.eval()\n",
        "        torch.save(model.state_dict(), \"temp.pt\")\n",
        "        with torch.no_grad():\n",
        "            valid_loss = valid_epoch(model, valid_loader)\n",
        "\n",
        "        if valid_loss.avg < best_loss:\n",
        "            best_loss = valid_loss.avg\n",
        "            torch.save(model.state_dict(), \"best.pt\")\n",
        "            print(\"Saved Best Model!\")\n",
        "\n",
        "        lr_scheduler.step(valid_loss.avg)\n",
        "    print(f\"CAREFUL! I had to skip {train_loader.dataset.skippedImgCount} to finish. This introduces heavy bias to whatever dataset[0] was at the time of training\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311,
          "referenced_widgets": [
            "4b346dee9612443ebb50fa15c0776e2f",
            "2fc74eededc844a3a60d1991a6f3ff9e",
            "41fb59f92a5b470eb5ca46f88da5bc00",
            "11405ab5e54a46839a47862305090cd0",
            "2aa8b107e1864aea8a48fc449a18e69b",
            "0b130feaec3547428609c006a966dc92",
            "4bcbdb8bf76e4b2aa366dbb1c6c4f23a",
            "8aab60baa4e34261940b1565a05f7084",
            "83765791877542fd8d512f01b36065ab",
            "0e737609f8474ca095bc89f05b30c378",
            "032a5b070fca4d518de0b0e834cb8ce5",
            "f2aad45036ed451493e19b4a7273bb62",
            "d00457ddd200439ebe52e835f0fadb8d",
            "813b8b813b844cf89b526dd10c7a3939",
            "165b6e337e3d4bc2a711dbbc2415f723",
            "78bed4ebcc7146a3a2b218ac5d74fde6",
            "aa3a5031b439493a9261f360f4673e55",
            "2adbe6b07a6747a8a6e9bfce8d0eb293",
            "7d5c7a5110984644a22da7e879c6e5a2",
            "d54e3ecb8d134a5eb8563b76cc510e72",
            "d2186d4488c74288be6c514f45ae9b4d",
            "6703cc11a5444e96845db0e1e4f5e6ab"
          ]
        },
        "id": "2G3S841Vi6le",
        "outputId": "4a22679b-4f30-4127-d037-bb525206e3a7"
      },
      "source": [
        "# Run to start training\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2aad45036ed451493e19b4a7273bb62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1843 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}