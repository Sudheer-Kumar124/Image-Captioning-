{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mzv2WiKvgJAl",
        "outputId": "35d24ce5-6d38-4e0b-c810-bb9c45f5c521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/virajbagal/roco-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading roco-dataset.zip to /home/sagemaker-user/xray-images\n",
            "100%|██████████████████████████████████████▉| 6.18G/6.19G [00:37<00:00, 143MB/s]\n",
            "100%|███████████████████████████████████████| 6.19G/6.19G [00:38<00:00, 175MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the ROCO dataset from Kaggle\n",
        "! kaggle datasets download virajbagal/roco-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udm313P8gJAq"
      },
      "outputs": [],
      "source": [
        "# Unzip the downloaded dataset\n",
        "! unzip roco-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUqhE7cJgJAr",
        "outputId": "c59809fc-880f-4413-cb01-16ed66483647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.9.0)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.18)\n",
            "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.7)\n",
            "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.14)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (69.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\n",
            "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.5.10)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.14)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/sagemaker-\n",
            "[nltk_data]     user/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/sagemaker-\n",
            "[nltk_data]     user/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /home/sagemaker-\n",
            "[nltk_data]     user/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Install necessary libraries: kaggle, spacy, and nltk\n",
        "!pip install kaggle\n",
        "!pip install spacy\n",
        "!pip install nltk\n",
        "\n",
        "# Import required libraries for data processing and manipulation\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "# Download and load the spaCy model for text processing\n",
        "!python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Download NLTK data for stopwords and lemmatizatio\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha4eVZV-gJAt"
      },
      "outputs": [],
      "source": [
        "# Load the dataset CSV files\n",
        "train_caption_df = pd.read_csv('/home/sagemaker-user/xray-images/all_data/test/radiologytestdata.csv')\n",
        "val_caption_df = pd.read_csv('/home/sagemaker-user/xray-images/all_data/validation/radiologyvaldata.csv')\n",
        "test_caption_df = pd.read_csv('/home/sagemaker-user/xray-images/all_data/test/radiologytestdata.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErZkEPUlRV6c"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess text by cleaning and normalizing\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|ftp\\S+', '', text) # removing the links\n",
        "    text = text.replace('\\n', ' ') # removing the new lines\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text) # removing the words containing numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # removing the spaces\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # removing special characters\n",
        "    words = text.split()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words] # considering only normal words\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words] # considering the stemmed words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words] #considering the lemmatized words\n",
        "    text = ' '.join(words)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryuAPn7vf1Yx"
      },
      "outputs": [],
      "source": [
        "# Reload the dataset CSV files\n",
        "train_caption_df = pd.read_csv('/home/sagemaker-user/xray-images/all_data/train/radiologytraindata.csv')\n",
        "val_caption_df = pd.read_csv('/home/sagemaker-user/xray-images/all_data/validation/radiologyvaldata.csv')\n",
        "test_caption_df = pd.read_csv('/home/sagemaker-user/xray-images/all_data/test/radiologytestdata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu5HUt4IRkxi"
      },
      "outputs": [],
      "source": [
        "# Apply text preprocessing to the caption data\n",
        "train_caption_df['cleaned_caption'] = train_caption_df['caption'].apply(preprocess_text)\n",
        "val_caption_df['cleaned_caption'] = val_caption_df['caption'].apply(preprocess_text)\n",
        "test_caption_df['cleaned_caption'] = test_caption_df['caption'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "plXBrDoqc5tB",
        "outputId": "ead83e23-9848-45c6-97d7-00661dc42b62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>caption</th>\n",
              "      <th>cleaned_caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ROCO_00002</td>\n",
              "      <td>PMC4083729_AMHSR-4-14-g002.jpg</td>\n",
              "      <td>Computed tomography scan in axial view showin...</td>\n",
              "      <td>comput tomographi scan axial view show obliter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ROCO_00003</td>\n",
              "      <td>PMC2837471_IJD2009-150251.001.jpg</td>\n",
              "      <td>Bacterial contamination occurred after comple...</td>\n",
              "      <td>bacteri contamin occur complet root canal trea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ROCO_00004</td>\n",
              "      <td>PMC2505281_11999_2007_30_Fig6_HTML.jpg</td>\n",
              "      <td>The patient had residual paralysis of the han...</td>\n",
              "      <td>patient residu paralysi hand poliomyel necessa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ROCO_00005</td>\n",
              "      <td>PMC3745845_IJD2013-683423.005.jpg</td>\n",
              "      <td>Panoramic radiograph after immediate loading.\\n</td>\n",
              "      <td>panoram radiograph immedi load</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ROCO_00007</td>\n",
              "      <td>PMC4917066_amjcaserep-17-301-g001.jpg</td>\n",
              "      <td>Plain abdomen x-ray: Multiple air levels at t...</td>\n",
              "      <td>plain abdomen xray multipl air level midabdome...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                    name  \\\n",
              "0  ROCO_00002          PMC4083729_AMHSR-4-14-g002.jpg   \n",
              "1  ROCO_00003       PMC2837471_IJD2009-150251.001.jpg   \n",
              "2  ROCO_00004  PMC2505281_11999_2007_30_Fig6_HTML.jpg   \n",
              "3  ROCO_00005       PMC3745845_IJD2013-683423.005.jpg   \n",
              "4  ROCO_00007   PMC4917066_amjcaserep-17-301-g001.jpg   \n",
              "\n",
              "                                             caption  \\\n",
              "0   Computed tomography scan in axial view showin...   \n",
              "1   Bacterial contamination occurred after comple...   \n",
              "2   The patient had residual paralysis of the han...   \n",
              "3    Panoramic radiograph after immediate loading.\\n   \n",
              "4   Plain abdomen x-ray: Multiple air levels at t...   \n",
              "\n",
              "                                     cleaned_caption  \n",
              "0  comput tomographi scan axial view show obliter...  \n",
              "1  bacteri contamin occur complet root canal trea...  \n",
              "2  patient residu paralysi hand poliomyel necessa...  \n",
              "3                     panoram radiograph immedi load  \n",
              "4  plain abdomen xray multipl air level midabdome...  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first few rows of the preprocessed training data\n",
        "train_caption_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1"
      ],
      "metadata": {
        "id": "iKihEQU6kyjL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL_66vAUgJAx"
      },
      "outputs": [],
      "source": [
        "# Define a function to preprocess images by resizing and normalizing\n",
        "def preprocess_image(image_path):\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        preprocess = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
        "        img_tensor = img_tensor.to(device)\n",
        "        return img_tensor\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"Cannot identify image file: {image_path}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stL_JHwDgJAy"
      },
      "outputs": [],
      "source": [
        "# Define directories for training, validation, and test images\n",
        "train_image_dirs = ['/home/sagemaker-user/xray-images/all_data/train/non-radiology/images/',\n",
        "                    '/home/sagemaker-user/xray-images/all_data/train/radiology/images/']\n",
        "val_image_dirs = ['/home/sagemaker-user/xray-images/all_data/validation/non-radiology/images/',\n",
        "                  '/home/sagemaker-user/xray-images/all_data/validation/radiology/images/']\n",
        "test_image_dirs = ['/home/sagemaker-user/xray-images/all_data/test/non-radiology/images/',\n",
        "                   '/home/sagemaker-user/xray-images/all_data/test/radiology/images/']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpctpQpqgJAy"
      },
      "outputs": [],
      "source": [
        "# Define a function to locate images in the specified directories\n",
        "def find_image(image_name, image_dirs):\n",
        "    for dir in image_dirs:\n",
        "        image_path = os.path.join(dir, image_name)\n",
        "        if os.path.exists(image_path):\n",
        "            return image_path\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxY02l2ygJAy"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store preprocessed data\n",
        "preprocessed_data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rARAsLdJgJAz"
      },
      "outputs": [],
      "source": [
        "# Define a function to process and save the dataset\n",
        "import torch\n",
        "\n",
        "def process_and_save_dataset(df, set_name, image_dirs):\n",
        "    preprocessed_data = []\n",
        "    max_samples = 1000\n",
        "    processed_samples = 0\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        if processed_samples >= max_samples:\n",
        "            break\n",
        "        image_path = find_image(row['name'], image_dirs)\n",
        "        if image_path:\n",
        "            preprocessed_image = preprocess_image(image_path)\n",
        "            if preprocessed_image is not None:\n",
        "                preprocessed_data.append((row['cleaned_caption'], preprocessed_image.cpu()))\n",
        "                processed_samples += 1\n",
        "        else:\n",
        "            print(f\"Image {row['name']} not found.\")\n",
        "\n",
        "    captions = [item[0] for item in preprocessed_data]\n",
        "    images = [item[1] for item in preprocessed_data]\n",
        "\n",
        "    # Save the preprocessed data to a .pt file\n",
        "    torch.save({'captions': captions, 'images': images}, f'{set_name}_preprocessed_data.pt')\n",
        "\n",
        "    print(f'{set_name} preprocessed data saved to {set_name}_preprocessed_data.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8Lwq2ZzgJAz"
      },
      "outputs": [],
      "source": [
        "# Define the device for computation (GPU if available, otherwise CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-O9UGfBgJAz",
        "outputId": "19a6fb4c-6fc5-4c3b-9485-7b67b2cbdefa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train preprocessed data saved to train_preprocessed_data.pt\n",
            "val preprocessed data saved to val_preprocessed_data.pt\n",
            "test preprocessed data saved to test_preprocessed_data.pt\n"
          ]
        }
      ],
      "source": [
        "# Process and save the training, validation, and test datasets\n",
        "process_and_save_dataset(train_caption_df, 'train', train_image_dirs)\n",
        "process_and_save_dataset(val_caption_df, 'val', val_image_dirs)\n",
        "process_and_save_dataset(test_caption_df, 'test', test_image_dirs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n280AFBygJA0",
        "outputId": "0a974ec4-ed43-4b46-db8b-cc983896fd5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /opt/conda/lib/python3.10/site-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.3.1)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (4.11.0)\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install torchtext for text processing\n",
        "pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2WYp9vjgJA3"
      },
      "outputs": [],
      "source": [
        "# Load the preprocessed dataset\n",
        "train_data = torch.load('train_preprocessed_data.pt')\n",
        "val_data = torch.load('val_preprocessed_data.pt')\n",
        "test_data = torch.load('test_preprocessed_data.pt')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThNnUgJtgJA3"
      },
      "outputs": [],
      "source": [
        "# Import required libraries for building and training the model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision.models as models\n",
        "\n",
        "# Tokenize the captions by splitting into words\n",
        "def tokenize_caption(caption):\n",
        "    return caption.split()\n",
        "\n",
        "# Build the vocabulary from the training captions\n",
        "def yield_tokens(data):\n",
        "    for caption in data['captions']:\n",
        "        yield tokenize_caption(caption)\n",
        "\n",
        "# Create a vocabulary object from the training captions\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "# Define a function to numericalize and pad the captions\n",
        "def numericalize_caption(caption, vocab, max_length=20):\n",
        "    tokens = tokenize_caption(caption)\n",
        "    tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
        "    token_ids = vocab(tokens)\n",
        "    if len(token_ids) < max_length:\n",
        "        token_ids += [vocab[\"<pad>\"]] * (max_length - len(token_ids))\n",
        "    else:\n",
        "        token_ids = token_ids[:max_length]\n",
        "    return torch.tensor(token_ids)\n",
        "\n",
        "# Define a custom dataset class for handling image-caption pairs\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, vocab, transform=None, max_length=20):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "        self.transform = transform\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['captions'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        caption = self.data['captions'][idx]\n",
        "        image = self.data['images'][idx]\n",
        "\n",
        "        # Ensure no extra dimension is added to the image tensor\n",
        "        caption = numericalize_caption(caption, self.vocab, self.max_length)\n",
        "        return image.squeeze(0), caption\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfbTdj3DgJA3"
      },
      "outputs": [],
      "source": [
        "# Create dataset objects for training, validation, and testing\n",
        "train_dataset = CustomDataset(train_data, vocab, transform=None)\n",
        "val_dataset = CustomDataset(val_data, vocab, transform=None)\n",
        "test_dataset = CustomDataset(test_data, vocab, transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZhEp5FxgJA4"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader instances for batching and shuffling data\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_zDRX3kgJA4"
      },
      "outputs": [],
      "source": [
        "# Define a custom model class for the image captioning task\n",
        "class ImageCaptioningModel(nn.Module):\n",
        "    def __init__(self, cnn_model_name, embed_size, hidden_size, vocab_size, num_layers):\n",
        "        super(ImageCaptioningModel, self).__init__()\n",
        "        self.cnn_model_name = cnn_model_name\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        if cnn_model_name == 'vgg':\n",
        "            self.cnn = models.vgg16(pretrained=True)\n",
        "            self.cnn.classifier[-1] = nn.Linear(self.cnn.classifier[-1].in_features, embed_size)\n",
        "        elif cnn_model_name == 'resnet':\n",
        "            self.cnn = models.resnet50(pretrained=True)\n",
        "            self.cnn.fc = nn.Linear(self.cnn.fc.in_features, embed_size)\n",
        "        elif cnn_model_name == 'efficientnet':\n",
        "            self.cnn = models.efficientnet_b0(pretrained=True)\n",
        "            self.cnn.classifier[-1] = nn.Linear(self.cnn.classifier[-1].in_features, embed_size)\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn_input_size = embed_size * 2  # Because we are concatenating CNN output and embedded captions\n",
        "        self.rnn = nn.LSTM(self.rnn_input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        cnn_out = self.cnn(images)\n",
        "        cnn_out = cnn_out.unsqueeze(1).repeat(1, captions.size(1), 1)\n",
        "\n",
        "        embedded_captions = self.embedding(captions)\n",
        "        rnn_input = torch.cat((cnn_out, embedded_captions), dim=2)\n",
        "\n",
        "        rnn_out, _ = self.rnn(rnn_input)\n",
        "        outputs = self.linear(rnn_out)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIbldp9ZgJA4"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, captions in train_loader:\n",
        "            images = images.to(model.device)\n",
        "            captions = captions.to(model.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, captions[:, :-1])\n",
        "            loss = criterion(outputs.reshape(-1, outputs.shape[2]), captions[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        for images, captions in test_loader:\n",
        "            images = images.to(model.device)\n",
        "            captions = captions.to(model.device)\n",
        "\n",
        "            outputs = model(images, captions[:, :-1])\n",
        "            loss = criterion(outputs.reshape(-1, outputs.shape[2]), captions[:, 1:].reshape(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "        print(f'Average Test Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-luf8uIgJA5",
        "outputId": "5417c534-3582-4599-a5de-2812134d1c10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training VGG Model\n",
            "Epoch [1/10], Loss: 5.8930\n",
            "Epoch [2/10], Loss: 5.1336\n",
            "Epoch [3/10], Loss: 4.0198\n",
            "Epoch [4/10], Loss: 4.9219\n",
            "Epoch [5/10], Loss: 5.5566\n",
            "Epoch [6/10], Loss: 4.9949\n",
            "Epoch [7/10], Loss: 5.9203\n",
            "Epoch [8/10], Loss: 5.6124\n",
            "Epoch [9/10], Loss: 3.7834\n",
            "Epoch [10/10], Loss: 5.8096\n",
            "Evaluating VGG Model\n",
            "Average Test Loss: 5.7654\n"
          ]
        }
      ],
      "source": [
        "# Set model parameters and initialize the model\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "vocab_size = len(vocab)\n",
        "num_layers = 1\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "vgg_model = ImageCaptioningModel('vgg', embed_size, hidden_size, vocab_size, num_layers).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_vgg = torch.optim.Adam(vgg_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train and Evaluate VGG Model\n",
        "print(\"Training VGG Model\")\n",
        "train_model(vgg_model, train_loader, criterion, optimizer_vgg, num_epochs)\n",
        "print(\"Evaluating VGG Model\")\n",
        "evaluate_model(vgg_model, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2\n"
      ],
      "metadata": {
        "id": "thxYqpVjkrS1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOJP6fvHicFA"
      },
      "outputs": [],
      "source": [
        "# Define image transformations: resize and convert to tenso\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
        "    transforms.ToTensor(),          # Convert the image to a tensor\n",
        "])\n",
        "\n",
        "# Define a function to preprocess images\n",
        "def preprocess_image(image_path):\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img_tensor = transform(img)  # Apply transformations\n",
        "        img_tensor = img_tensor.permute(1, 2, 0)\n",
        "        img_tensor = img_tensor.to(device)  # Move the tensor to the specified device\n",
        "        img_tensor = img_tensor.cpu().numpy()\n",
        "        return img_tensor\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"Cannot identify image file: {image_path}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXYvGqB1f22-"
      },
      "outputs": [],
      "source": [
        "# Define directories where images can be located\n",
        "train_image_dirs = ['/home/sagemaker-user/xray-images/all_data/train/non-radiology/images/',\n",
        "                    '/home/sagemaker-user/xray-images/all_data/train/radiology/images/']\n",
        "val_image_dirs = ['/home/sagemaker-user/xray-images/all_data/validation/non-radiology/images/',\n",
        "                  '/home/sagemaker-user/xray-images/all_data/validation/radiology/images/']\n",
        "test_image_dirs = ['/home/sagemaker-user/xray-images/all_data/test/non-radiology/images/',\n",
        "                   '/home/sagemaker-user/xray-images/all_data/test/radiology/images/']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQCU5IDigq99"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define a function to find the image in the specified directories\n",
        "def find_image(image_name, image_dirs):\n",
        "    for dir in image_dirs:\n",
        "        image_path = os.path.join(dir, image_name)\n",
        "        if os.path.exists(image_path):\n",
        "            return image_path\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8vRuck5gzi5"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store preprocessed data\n",
        "preprocessed_data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaivMzuXiX9m"
      },
      "outputs": [],
      "source": [
        "# Define the device for computation (GPU if available, otherwise CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqGHVYAvg4KW"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for data manipulation\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Define a function to process and save the dataset\n",
        "def process_and_save_dataset(df, set_name, image_dirs):\n",
        "    preprocessed_data = []\n",
        "    max_samples = 1000\n",
        "    processed_samples = 0\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        if processed_samples >= max_samples:\n",
        "            break\n",
        "        image_path = find_image(row['name'], image_dirs)\n",
        "        if image_path:\n",
        "            preprocessed_image = preprocess_image(image_path)\n",
        "            if preprocessed_image is not None:\n",
        "                preprocessed_data.append((row['cleaned_caption'], preprocessed_image))\n",
        "                processed_samples += 1\n",
        "        else:\n",
        "            print(f\"Image {row['name']} not found.\")\n",
        "\n",
        "    # Create a DataFrame from the preprocessed data\n",
        "    preprocessed_df = pd.DataFrame(preprocessed_data, columns=['cleaned_caption', 'image_tensor'])\n",
        "\n",
        "    print(f'{set_name} preprocessed data has been stored in a DataFrame.')\n",
        "\n",
        "    return preprocessed_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHxUIpDCn4Y6",
        "outputId": "0539f17e-9ce7-4cfb-d407-ab6c380c85cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train preprocessed data has been stored in a DataFrame.\n",
            "val preprocessed data has been stored in a DataFrame.\n",
            "test preprocessed data has been stored in a DataFrame.\n"
          ]
        }
      ],
      "source": [
        "# Process and save the training, validation, and test datasets\n",
        "train_preprocessed_df = process_and_save_dataset(train_caption_df, 'train', train_image_dirs)\n",
        "val_preprocessed_df = process_and_save_dataset(val_caption_df, 'val', val_image_dirs)\n",
        "test_preprocessed_df = process_and_save_dataset(test_caption_df, 'test', test_image_dirs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "uxvqHtR5NeTu",
        "outputId": "ddbb32e7-54d9-4f6a-9537-ee194afb0576"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_caption</th>\n",
              "      <th>image_tensor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>comput tomographi scan axial view show obliter...</td>\n",
              "      <td>[[[0.16078432, 0.15294118, 0.15686275], [0.164...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bacteri contamin occur complet root canal trea...</td>\n",
              "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>patient residu paralysi hand poliomyel necessa...</td>\n",
              "      <td>[[[0.4117647, 0.4117647, 0.4117647], [0.211764...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>panoram radiograph immedi load</td>\n",
              "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plain abdomen xray multipl air level midabdome...</td>\n",
              "      <td>[[[0.47843137, 0.47843137, 0.47843137], [0.388...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     cleaned_caption  \\\n",
              "0  comput tomographi scan axial view show obliter...   \n",
              "1  bacteri contamin occur complet root canal trea...   \n",
              "2  patient residu paralysi hand poliomyel necessa...   \n",
              "3                     panoram radiograph immedi load   \n",
              "4  plain abdomen xray multipl air level midabdome...   \n",
              "\n",
              "                                        image_tensor  \n",
              "0  [[[0.16078432, 0.15294118, 0.15686275], [0.164...  \n",
              "1  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...  \n",
              "2  [[[0.4117647, 0.4117647, 0.4117647], [0.211764...  \n",
              "3  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...  \n",
              "4  [[[0.47843137, 0.47843137, 0.47843137], [0.388...  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first few rows of the preprocessed training data\n",
        "train_preprocessed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mraMDOTVN9Zn"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for text processing and model building\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI7EiEfQN7W3"
      },
      "outputs": [],
      "source": [
        "# Define a function to preprocess text by tokenizing and sequencing\n",
        "def preprocess_text(captions):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(captions)\n",
        "    sequences = tokenizer.texts_to_sequences(captions)\n",
        "    max_length = max(len(seq) for seq in sequences)\n",
        "    word_index = tokenizer.word_index\n",
        "    vocab_size = len(word_index) + 1\n",
        "\n",
        "    return tokenizer, max_length, vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNo2qlFCOL9v"
      },
      "outputs": [],
      "source": [
        "# Preprocess the training captions\n",
        "train_captions = train_preprocessed_df['cleaned_caption']\n",
        "tokenizer, max_length, vocab_size = preprocess_text(train_captions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIAjrr9wOVKv"
      },
      "outputs": [],
      "source": [
        "# Define a function to create sequences for model input\n",
        "def create_sequences(tokenizer, max_length, descriptions, photos):\n",
        "    X1, X2, y = [], [], []\n",
        "    for i in range(len(descriptions)):\n",
        "        desc = descriptions[i]\n",
        "        photo = photos[i]\n",
        "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
        "        for j in range(1, len(seq)):\n",
        "            in_seq, out_seq = seq[:j], seq[j]\n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "            out_seq_vec = np.zeros(vocab_size)\n",
        "            out_seq_vec[out_seq] = 1\n",
        "            X1.append(photo)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq_vec)\n",
        "    return np.array(X1), np.array(X2), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kmhvkU6OZzW"
      },
      "outputs": [],
      "source": [
        "# Create sequences for training data\n",
        "X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_preprocessed_df['cleaned_caption'],train_preprocessed_df['image_tensor'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwQIJhZwOqUW",
        "outputId": "27ef5e7a-4d7f-4f5b-9a71-da1916ba5d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 78)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 78, 256)              814080    ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " inception_v3 (Functional)   (None, 2048)                 2180278   ['input_4[0][0]']             \n",
            "                                                          4                                       \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 78, 256)              0         ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  524544    ['inception_v3[0][0]']        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 256)                  525312    ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 256)                  0         ['dense_3[0][0]',             \n",
            "                                                                     'lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 256)                  65792     ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 3180)                 817260    ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24549772 (93.65 MB)\n",
            "Trainable params: 2746988 (10.48 MB)\n",
            "Non-trainable params: 21802784 (83.17 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the image captioning model using InceptionV3 and LSTM\n",
        "def define_model(vocab_size, max_length):\n",
        "    inputs1 = Input(shape=(224, 224, 3))\n",
        "    model = InceptionV3(include_top=False, pooling='avg')\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    fe1 = model(inputs1)\n",
        "    fe2 = Dense(256, activation='relu')(fe1)\n",
        "\n",
        "    inputs2 = Input(shape=(max_length,))\n",
        "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "    se2 = Dropout(0.5)(se1)\n",
        "    se3 = LSTM(256)(se2)\n",
        "\n",
        "    decoder1 = add([fe2, se3])\n",
        "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = define_model(vocab_size, max_length)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTFtIPG2PTXs"
      },
      "outputs": [],
      "source": [
        "# Set training parameters\n",
        "epochs = 10\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBa_3GaRPbOz"
      },
      "outputs": [],
      "source": [
        "# Compile the model with additional accuracy metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU2ZYVidPeYr",
        "outputId": "0013df2f-9dae-4d9a-9e8d-bccf0c67bd9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-05 10:09:18.735804: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6147563520 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 136s 814ms/step - loss: 7.2387 - accuracy: 0.0397 - val_loss: 7.0585 - val_accuracy: 0.0431\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 127s 793ms/step - loss: 6.5924 - accuracy: 0.0502 - val_loss: 7.1526 - val_accuracy: 0.0521\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 127s 793ms/step - loss: 6.1538 - accuracy: 0.0685 - val_loss: 7.1406 - val_accuracy: 0.0678\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 127s 795ms/step - loss: 5.6230 - accuracy: 0.0871 - val_loss: 7.2780 - val_accuracy: 0.0776\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 127s 794ms/step - loss: 5.0209 - accuracy: 0.1083 - val_loss: 7.6905 - val_accuracy: 0.0732\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 127s 797ms/step - loss: 4.3645 - accuracy: 0.1301 - val_loss: 8.1476 - val_accuracy: 0.0638\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 127s 796ms/step - loss: 3.7622 - accuracy: 0.1604 - val_loss: 8.8571 - val_accuracy: 0.0674\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 128s 802ms/step - loss: 3.2460 - accuracy: 0.2154 - val_loss: 9.2397 - val_accuracy: 0.0701\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 128s 799ms/step - loss: 2.8289 - accuracy: 0.2699 - val_loss: 9.9721 - val_accuracy: 0.0615\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 128s 799ms/step - loss: 2.4735 - accuracy: 0.3375 - val_loss: 10.7784 - val_accuracy: 0.0623\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit([X1train, X2train], ytrain, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7hbYHYHLXfy3",
        "outputId": "0aab7bec-8de0-40f6-c11d-7c5366302c79"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Access and plot training and validation accuracy\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ooiyd3YMXiYi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR7jsGl8gJBQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}