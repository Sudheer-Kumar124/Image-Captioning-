{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324d279e-a5f7-42a0-bebd-dfacbaf7eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gowsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gowsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gowsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed captions saved to 'C:\\Users\\gowsh\\OneDrive\\Desktop\\Building AI Model\\dataset\\preprocessed_captions.txt' successfully.\n",
      "Sample of preprocessed captions:\n",
      "Original Caption: 1000268201_693b08cb0e.jpg,A child in a pink dress is climbing up a set of stairs in an entry way .\n",
      "preprocessed Caption: 1000268201_693b08cb0e.jpg\tchild pink dress climbing set stair entry way\n",
      "\n",
      "Original Caption: 1000268201_693b08cb0e.jpg,A girl going into a wooden building .\n",
      "preprocessed Caption: 1000268201_693b08cb0e.jpg\tgirl going wooden building\n",
      "\n",
      "Original Caption: 1000268201_693b08cb0e.jpg,A little girl climbing into a wooden playhouse .\n",
      "preprocessed Caption: 1000268201_693b08cb0e.jpg\tlittle girl climbing wooden playhouse\n",
      "\n",
      "Original Caption: 1000268201_693b08cb0e.jpg,A little girl climbing the stairs to her playhouse .\n",
      "preprocessed Caption: 1000268201_693b08cb0e.jpg\tlittle girl climbing stair playhouse\n",
      "\n",
      "Original Caption: 1000268201_693b08cb0e.jpg,A little girl in a pink dress going into a wooden cabin .\n",
      "preprocessed Caption: 1000268201_693b08cb0e.jpg\tlittle girl pink dress going wooden cabin\n",
      "\n",
      "Original Caption: 1001773457_577c3a7d70.jpg,A black dog and a spotted dog are fighting\n",
      "preprocessed Caption: 1001773457_577c3a7d70.jpg\tblack dog spotted dog fighting\n",
      "\n",
      "Original Caption: 1001773457_577c3a7d70.jpg,A black dog and a tri-colored dog playing with each other on the road .\n",
      "preprocessed Caption: 1001773457_577c3a7d70.jpg\tblack dog tricolored dog playing road\n",
      "\n",
      "Original Caption: 1001773457_577c3a7d70.jpg,A black dog and a white dog with brown spots are staring at each other in the street .\n",
      "preprocessed Caption: 1001773457_577c3a7d70.jpg\tblack dog white dog brown spot staring street\n",
      "\n",
      "Original Caption: 1001773457_577c3a7d70.jpg,Two dogs of different breeds looking at each other on the road .\n",
      "preprocessed Caption: 1001773457_577c3a7d70.jpg\ttwo dog different breed looking road\n",
      "\n",
      "Original Caption: 1001773457_577c3a7d70.jpg,Two dogs on pavement moving toward each other .\n",
      "preprocessed Caption: 1001773457_577c3a7d70.jpg\ttwo dog pavement moving toward\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import os\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    # Remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Join the words back into a string\n",
    "    preprocessed_text = ' '.join(words)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# File paths\n",
    "caption_file = r'C:\\Users\\gowsh\\OneDrive\\Desktop\\Building AI Model\\dataset\\captions.txt'\n",
    "output_file = r'C:\\Users\\gowsh\\OneDrive\\Desktop\\Building AI Model\\dataset\\preprocessed_captions.txt'\n",
    "\n",
    "# Check if the caption file exists\n",
    "if not os.path.isfile(caption_file):\n",
    "    print(f\"Error: Caption file '{caption_file}' not found.\")\n",
    "else:\n",
    "    # Read captions from the file\n",
    "    with open(caption_file, 'r', encoding='utf-8') as file:\n",
    "        captions = file.readlines()\n",
    "    \n",
    "    # Skip the header line and process each caption\n",
    "    preprocessed_captions = []\n",
    "    for caption in captions[1:]:  # Skip the header line\n",
    "        # Split the line to get image ID and caption\n",
    "        parts = caption.strip().split(',', 1)  # Split by the first comma\n",
    "        if len(parts) != 2:\n",
    "            print(f\"Error: Invalid format in line: {caption.strip()}\")\n",
    "            continue\n",
    "        \n",
    "        img_id, caption_text = parts\n",
    "        preprocessed_caption = preprocess_text(caption_text)\n",
    "        preprocessed_captions.append((img_id, preprocessed_caption))\n",
    "    \n",
    "    # Save preprocessed captions to a new file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for img_id, preprocessed_caption in preprocessed_captions:\n",
    "            file.write(f\"{img_id},{preprocessed_caption}\\n\")\n",
    "\n",
    "    print(f\"preprocessed captions saved to '{output_file}' successfully.\")\n",
    "\n",
    "    # Print a limited number of preprocessed captions for demonstration\n",
    "    print(\"Sample of preprocessed captions:\")\n",
    "    for i in range(min(10, len(preprocessed_captions))):  # Print only the first 10 for demonstration\n",
    "        img_id, preprocessed_caption = preprocessed_captions[i]\n",
    "        print(f\"Original Caption: {captions[i+1].strip()}\")  # captions[i+1] because we skipped the header\n",
    "        print(f\"preprocessed Caption: {img_id}\\t{preprocessed_caption}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64758ab-41bd-4c0e-8c48-1ed5fd041910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
